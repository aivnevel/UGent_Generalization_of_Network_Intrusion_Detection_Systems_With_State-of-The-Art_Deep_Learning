{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eerste getrainde model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies installeren (Feather & Multithreading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-2.0.0-cp38-cp38-manylinux2014_x86_64.whl (17.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.8 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.8/site-packages (from pyarrow) (1.18.5)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-2.0.0\n",
      "Collecting pathos\n",
      "  Downloading pathos-0.2.6.zip (219 kB)\n",
      "\u001b[K     |████████████████████████████████| 219 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ppft>=1.6.6.2\n",
      "  Downloading ppft-1.6.6.3-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.5 MB/s eta 0:00:010:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: dill>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from pathos) (0.3.2)\n",
      "Collecting pox>=0.2.8\n",
      "  Downloading pox-0.2.9-py2.py3-none-any.whl (30 kB)\n",
      "Collecting multiprocess>=0.70.10\n",
      "  Downloading multiprocess-0.70.10.zip (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.7.3 in /opt/conda/lib/python3.8/site-packages (from ppft>=1.6.6.2->pathos) (1.15.0)\n",
      "Building wheels for collected packages: pathos, multiprocess\n",
      "  Building wheel for pathos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathos: filename=pathos-0.2.6-py3-none-any.whl size=77675 sha256=1841f21afd40d11645647df985559db169273877e8cc96352f4ddd558567f884\n",
      "  Stored in directory: /home/aivnevel/.cache/pip/wheels/83/12/43/a7b335eac30d213e8cbe768bff7456ef4bc76351769864dd79\n",
      "  Building wheel for multiprocess (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multiprocess: filename=multiprocess-0.70.10-py3-none-any.whl size=125838 sha256=ff57943bc0e485db2311eb7ea2d5db328e8cc523060717e5c982a735aeaf475e\n",
      "  Stored in directory: /home/aivnevel/.cache/pip/wheels/f4/c7/82/0bcdc3506e6a8365963db24f477b81693438d4b9165c0757b7\n",
      "Successfully built pathos multiprocess\n",
      "Installing collected packages: ppft, pox, multiprocess, pathos\n",
      "Successfully installed multiprocess-0.70.10 pathos-0.2.6 pox-0.2.9 ppft-1.6.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "!pip install --upgrade pathos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DIR = './Datasets/local/'\n",
    "\n",
    "names = []\n",
    "dfs = {}\n",
    "for filename in os.listdir(DIR):\n",
    "    dfs[filename] = pd.read_feather(DIR + filename)\n",
    "    names.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models trained with balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathos.pools as pp\n",
    "import multiprocessing as mp\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def create_SVC_model(df):\n",
    "    df_result = df['label']\n",
    "    df = df.drop(['label'], axis=1)\n",
    "    clf = make_pipeline(MinMaxScaler(), LinearSVC(dual=False, tol=1e-5, max_iter=64000, class_weight='balanced'))\n",
    "    clf.fit(df, df_result)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pp.ProcessPool(mp.cpu_count())\n",
    "models_balanced = p.map(lambda key: create_SVC_model(dfs[key]), dfs.keys())\n",
    "p.close()\n",
    "p.join()\n",
    "p.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_SVC_model(dfs['cicdos2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Weighted average: 0.6279268622264754\n",
      "\t\t F1 score: 0.6364474612664015\n"
     ]
    }
   ],
   "source": [
    "df_test = dfs[names[0]]\n",
    "df_testresult = df_test['label']\n",
    "df_test = df_test.drop(['label'], axis=1)\n",
    "y_test_clf_model = model.predict(df_test)\n",
    "print(\"\\t\\t\", \"Weighted average:\", accuracy_score(df_testresult, y_test_clf_model))\n",
    "print(\"\\t\\t\", \"F1 score:\", f1_score(df_testresult, y_test_clf_model, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "it = 0\n",
    "for model in models_balanced:\n",
    "    dump(model, './models/svm/balanced/fully_trained/'+ names[it] + '.joblib') \n",
    "    it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "clf = {}\n",
    "it = 0\n",
    "for name in names:\n",
    "    clf[name] = load('./models/svm/balanced/fully_trained/'+ names[it] + '.joblib') \n",
    "    it+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy & F1 Score\n",
    "Accuracy:\n",
    "    Accuracy = TP / (TP + FP + FN + TN) \n",
    "F1 score:\n",
    "    F1 = TP/ (TP + 1/2 * (FP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for key, model in clf.items():\n",
    "    print(key,\":\")\n",
    "    for j, path2 in dfs.items():\n",
    "        df_test = dfs[j]\n",
    "        df_testresult = df_test['label']\n",
    "        df_test = df_test.drop(['label'], axis=1)\n",
    "        y_test_clf_model = model.predict(df_test)\n",
    "        print(\"\\t\", j,\":\")\n",
    "        print(\"\\t\\t\", \"Weighted average:\", accuracy_score(df_testresult, y_test_clf_model))\n",
    "        print(\"\\t\\t\", \"F1 score:\", f1_score(df_testresult, y_test_clf_model, average='binary'))\n",
    "    print(\"----------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
